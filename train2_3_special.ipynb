{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src ='./02.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. import Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import mediapipe as mp\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import torch\n",
    "from facenet_pytorch import MTCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands()\n",
    "mp_draw = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function calculate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateangle(a,b,c):\n",
    "    a = np.array(a) # First \n",
    "    b = np.array(b) # Mid \n",
    "    c = np.array(c) # End \n",
    "\n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    triangle = np.abs(radians*180.0/np.pi)\n",
    "\n",
    "    if triangle > 180.0:\n",
    "        triangle = 360-triangle\n",
    "    \n",
    "    return triangle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test Detection and Drawing landmarks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained MTCNN model\n",
    "mtcnn = MTCNN(keep_all=True, device=torch.device('cuda:0' if torch.cuda.is_available() else 'cpu'))\n",
    "\n",
    "cap = cv2.VideoCapture('./self_train.mp4')\n",
    "# cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Setup Mediapipe instance\n",
    "counter = 0\n",
    "stage = None\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5,\n",
    "                  min_tracking_confidence=0.5) as pose:\n",
    "    with mp_hands.Hands(static_image_mode=True, max_num_hands=2, min_detection_confidence=0.5) as hands:\n",
    "\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"Stream stopped.\")\n",
    "                break\n",
    "\n",
    "            # Perform face detection\n",
    "            boxes, probs = mtcnn.detect(frame)\n",
    "\n",
    "            if boxes is not None:\n",
    "                for box in boxes:\n",
    "                    x, y, width, height = map(int, box)\n",
    "                    \n",
    "                    # size detection face\n",
    "                    padding_percentage = 0.1  # 10% of the box size\n",
    "                    padding_x = int((width - x) * padding_percentage)\n",
    "                    padding_y = int((height - y) * padding_percentage)\n",
    "\n",
    "                    x -= padding_x\n",
    "                    y -= padding_y\n",
    "                    width += 2 * padding_x\n",
    "                    height += 2 * padding_y\n",
    "\n",
    "                    cv2.rectangle(frame, (x, y), (width, height), (0, 0, 255), 2)\n",
    "            \n",
    "            # Recolor image to RGB\n",
    "            frame.flags.writeable = False\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            results = pose.process(frame)\n",
    "            results_h = hands.process(frame)\n",
    "\n",
    "            # Recolor back to BRG\n",
    "            frame.flags.writeable = True\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            # Extract landmarks\n",
    "            try:\n",
    "                lanmarks = results.pose_landmarks.landmark\n",
    "\n",
    "                # Get coordinates\n",
    "                shoulder = [lanmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, lanmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "                elbow = [lanmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x, lanmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "                wrist = [lanmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x, lanmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "                \n",
    "                shoulder1 = [lanmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x, lanmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "                elbow1 = [lanmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x, lanmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "                wrist1 = [lanmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x, lanmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "                \n",
    "                # Calculate angle\n",
    "                triangle = calculateangle(shoulder, elbow, wrist).round(2)\n",
    "                triangle2 = calculateangle(shoulder1, elbow1, wrist1).round(2)\n",
    "                # print(angle)\n",
    "\n",
    "                # Visualize triangle shoulder, elbow, wrist\n",
    "                cv2.putText(frame, str(triangle),\n",
    "                            (int(elbow[0]*frame.shape[1]), int(elbow[1]*frame.shape[0])),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 2, cv2.LINE_AA)\n",
    "                \n",
    "                # Visualize triangle hip, shoulder1, elbow1\n",
    "                cv2.putText(frame, str(triangle2),\n",
    "                            (int(elbow1[0]*frame.shape[1]), int(elbow1[1]*frame.shape[0])),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 2, cv2.LINE_AA)\n",
    "                \n",
    "                # Curl Counter Logic\n",
    "                if triangle2 > 150:\n",
    "                    stage = \"down\"\n",
    "                if triangle2 < 30 and stage =='down':\n",
    "                    stage=\"up\"\n",
    "                    counter +=1\n",
    "                    # print(counter)\n",
    "\n",
    "                # Render curl counter\n",
    "                # Setup status box\n",
    "                cv2.rectangle(frame, (0,0), (250,73), (245,117,16), -1)\n",
    "                \n",
    "                # Rep data\n",
    "                cv2.putText(frame, 'REPS', (15,12), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)\n",
    "                cv2.putText(frame, str(counter), \n",
    "                            (10,60), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 2, cv2.LINE_AA)\n",
    "                \n",
    "                # Stage data\n",
    "                cv2.putText(frame, 'STAGE', (65,12), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)\n",
    "                cv2.putText(frame, stage, \n",
    "                            (60,60), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 2, cv2.LINE_AA)\n",
    "\n",
    "                # Render detections\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    frame,\n",
    "                    results.pose_landmarks,\n",
    "                    mp_pose.POSE_CONNECTIONS,\n",
    "                    mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2),\n",
    "                    mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2))\n",
    "                    # landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n",
    "                \n",
    "                if results_h.multi_hand_landmarks:\n",
    "                    for hand_landmarks in results_h.multi_hand_landmarks:\n",
    "                        mp_draw.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            cv2.imshow('MediaPipe Pose', frame)\n",
    "            \n",
    "            if cv2.waitKey(1) == ord('q'):\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Capture landmarks & Create DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks_2 = ['class']\n",
    "for val in range(1,33+1):\n",
    "    landmarks_2 += ['x{}'.format(val), 'y{}'.format(val), 'z{}'.format(val), 'v{}'.format(val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('coords_film.csv', mode='w', newline='') as f:\n",
    "    csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    csv_writer.writerow(landmarks_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_landmarks(results, action):\n",
    "    try:\n",
    "        keypoints = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten().tolist()\n",
    "        keypoints.insert(0, action)\n",
    "\n",
    "        with open('coords_film.csv', mode='a', newline='') as f:\n",
    "            csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "            csv_writer.writerow(keypoints)\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Record Dataframe From Pose Landmarks**\n",
    "- Record manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stream stopped.\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('./thank.mp4')\n",
    "cap = cv2.VideoCapture('./self_train.mp4')\n",
    "# cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Setup Mediapipe instance\n",
    "counter = 0\n",
    "stage = None\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5,\n",
    "                  min_tracking_confidence=0.5) as pose:\n",
    "    with mp_hands.Hands(static_image_mode=True, max_num_hands=2, min_detection_confidence=0.5) as hands:\n",
    "\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"Stream stopped.\")\n",
    "                break\n",
    "\n",
    "            # Recolor image to RGB\n",
    "            frame.flags.writeable = False\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            results = pose.process(frame)\n",
    "            results_h = hands.process(frame)\n",
    "\n",
    "            # Recolor back to BRG\n",
    "            frame.flags.writeable = True\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            # Extract landmarks\n",
    "            try:\n",
    "                lanmarks = results.pose_landmarks.landmark\n",
    "\n",
    "                # Get coordinates\n",
    "                shoulder = [lanmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, lanmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "                elbow = [lanmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x, lanmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "                wrist = [lanmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x, lanmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "                \n",
    "                shoulder1 = [lanmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x, lanmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "                elbow1 = [lanmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x, lanmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "                wrist1 = [lanmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x, lanmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "                \n",
    "                # Calculate angle\n",
    "                triangle = calculateangle(shoulder, elbow, wrist).round(2)\n",
    "                triangle2 = calculateangle(shoulder1, elbow1, wrist1).round(2)\n",
    "                # print(angle)\n",
    "\n",
    "                # Visualize triangle shoulder, elbow, wrist\n",
    "                cv2.putText(frame, str(triangle),\n",
    "                            (int(elbow[0]*frame.shape[1]), int(elbow[1]*frame.shape[0])),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 2, cv2.LINE_AA)\n",
    "                \n",
    "                # Visualize triangle shoulder1, elbow1, wrist1\n",
    "                cv2.putText(frame, str(triangle2),\n",
    "                            (int(elbow1[0]*frame.shape[1]), int(elbow1[1]*frame.shape[0])),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 2, cv2.LINE_AA)\n",
    "                \n",
    "                # Curl Counter Logic\n",
    "                if triangle2 > 150:\n",
    "                    stage = \"down\"\n",
    "                if triangle2 < 30 and stage =='down':\n",
    "                    stage=\"up\"\n",
    "                    counter +=1\n",
    "                    # print(counter)\n",
    "                \n",
    "                # Render curl counter\n",
    "                # Setup status box\n",
    "                cv2.rectangle(frame, (0,0), (250,73), (245,117,16), -1)\n",
    "                \n",
    "                # Rep data\n",
    "                cv2.putText(frame, 'REPS', (15,12), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)\n",
    "                cv2.putText(frame, str(counter), \n",
    "                            (10,60), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 2, cv2.LINE_AA)\n",
    "                \n",
    "                # Stage data\n",
    "                cv2.putText(frame, 'STAGE', (65,12), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)\n",
    "                cv2.putText(frame, stage, \n",
    "                            (80,60), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 2, cv2.LINE_AA)\n",
    "\n",
    "                # Render detections\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    frame,\n",
    "                    results.pose_landmarks,\n",
    "                    mp_pose.POSE_CONNECTIONS,\n",
    "                    mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2),\n",
    "                    mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2))\n",
    "                    # landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n",
    "                \n",
    "                if results_h.multi_hand_landmarks:\n",
    "                    for hand_landmarks in results_h.multi_hand_landmarks:\n",
    "                        mp_draw.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "                \n",
    "\n",
    "            cv2.imshow('MediaPipe Pose', frame)\n",
    "            \n",
    "            k = cv2.waitKey(1)\n",
    "            if k == ord('1'):\n",
    "                export_landmarks(results, 'want')\n",
    "            if k == ord('2'):\n",
    "                export_landmarks(results, \"don't want\")\n",
    "            if k == ord('3'):\n",
    "                export_landmarks(results, 'more')\n",
    "            if k == ord('4'):\n",
    "                export_landmarks(results, 'potty')\n",
    "            if k == ord('5'):\n",
    "                export_landmarks(results, 'dirty')\n",
    "            if k == ord('6'):\n",
    "                export_landmarks(results, 'clean')\n",
    "            if k == ord('7'):\n",
    "                export_landmarks(results, 'home')\n",
    "            if k == ord('8'):\n",
    "                export_landmarks(results, 'school') \n",
    "            if k == ord('9'):\n",
    "                export_landmarks(results, 'play')\n",
    "            if k == ord('0'):\n",
    "                export_landmarks(results, 'bed')  \n",
    "\n",
    "            if cv2.waitKey(1) == ord('q'):\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Train Machine Learning Classification Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.1 Read in Collected Data and Process**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_film = pd.read_csv('coords_film.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.read_csv('coords_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_thank = pd.read_csv('coords_thank.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ori = pd.read_csv('coords_ori.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat([df_film, df_new, df_thank,df_ori], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>z1</th>\n",
       "      <th>v1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>z2</th>\n",
       "      <th>v2</th>\n",
       "      <th>x3</th>\n",
       "      <th>...</th>\n",
       "      <th>z31</th>\n",
       "      <th>v31</th>\n",
       "      <th>x32</th>\n",
       "      <th>y32</th>\n",
       "      <th>z32</th>\n",
       "      <th>v32</th>\n",
       "      <th>x33</th>\n",
       "      <th>y33</th>\n",
       "      <th>z33</th>\n",
       "      <th>v33</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>want</td>\n",
       "      <td>0.523251</td>\n",
       "      <td>0.450990</td>\n",
       "      <td>-0.459594</td>\n",
       "      <td>0.999819</td>\n",
       "      <td>0.533429</td>\n",
       "      <td>0.417930</td>\n",
       "      <td>-0.431221</td>\n",
       "      <td>0.999746</td>\n",
       "      <td>0.539272</td>\n",
       "      <td>...</td>\n",
       "      <td>0.297255</td>\n",
       "      <td>0.010767</td>\n",
       "      <td>0.526460</td>\n",
       "      <td>1.816151</td>\n",
       "      <td>-0.012140</td>\n",
       "      <td>0.006274</td>\n",
       "      <td>0.441641</td>\n",
       "      <td>1.810452</td>\n",
       "      <td>0.018783</td>\n",
       "      <td>0.009043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>want</td>\n",
       "      <td>0.524013</td>\n",
       "      <td>0.449159</td>\n",
       "      <td>-0.515879</td>\n",
       "      <td>0.999908</td>\n",
       "      <td>0.534502</td>\n",
       "      <td>0.416850</td>\n",
       "      <td>-0.491419</td>\n",
       "      <td>0.999874</td>\n",
       "      <td>0.540472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.423895</td>\n",
       "      <td>0.005330</td>\n",
       "      <td>0.554579</td>\n",
       "      <td>1.776513</td>\n",
       "      <td>0.108589</td>\n",
       "      <td>0.003069</td>\n",
       "      <td>0.477024</td>\n",
       "      <td>1.773829</td>\n",
       "      <td>0.141674</td>\n",
       "      <td>0.004596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>want</td>\n",
       "      <td>0.524378</td>\n",
       "      <td>0.448990</td>\n",
       "      <td>-0.524086</td>\n",
       "      <td>0.999916</td>\n",
       "      <td>0.534832</td>\n",
       "      <td>0.416744</td>\n",
       "      <td>-0.500241</td>\n",
       "      <td>0.999885</td>\n",
       "      <td>0.540848</td>\n",
       "      <td>...</td>\n",
       "      <td>0.435331</td>\n",
       "      <td>0.004874</td>\n",
       "      <td>0.554528</td>\n",
       "      <td>1.776742</td>\n",
       "      <td>0.098729</td>\n",
       "      <td>0.002805</td>\n",
       "      <td>0.476732</td>\n",
       "      <td>1.773951</td>\n",
       "      <td>0.149873</td>\n",
       "      <td>0.004227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>want</td>\n",
       "      <td>0.525125</td>\n",
       "      <td>0.448920</td>\n",
       "      <td>-0.509409</td>\n",
       "      <td>0.999923</td>\n",
       "      <td>0.535406</td>\n",
       "      <td>0.416669</td>\n",
       "      <td>-0.486281</td>\n",
       "      <td>0.999894</td>\n",
       "      <td>0.541555</td>\n",
       "      <td>...</td>\n",
       "      <td>0.419291</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>0.553707</td>\n",
       "      <td>1.776260</td>\n",
       "      <td>0.100837</td>\n",
       "      <td>0.002565</td>\n",
       "      <td>0.476286</td>\n",
       "      <td>1.773094</td>\n",
       "      <td>0.135557</td>\n",
       "      <td>0.003885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>want</td>\n",
       "      <td>0.525927</td>\n",
       "      <td>0.448911</td>\n",
       "      <td>-0.530385</td>\n",
       "      <td>0.999929</td>\n",
       "      <td>0.535953</td>\n",
       "      <td>0.416656</td>\n",
       "      <td>-0.506059</td>\n",
       "      <td>0.999903</td>\n",
       "      <td>0.542202</td>\n",
       "      <td>...</td>\n",
       "      <td>0.417702</td>\n",
       "      <td>0.004097</td>\n",
       "      <td>0.551577</td>\n",
       "      <td>1.776931</td>\n",
       "      <td>0.101532</td>\n",
       "      <td>0.002363</td>\n",
       "      <td>0.473619</td>\n",
       "      <td>1.773873</td>\n",
       "      <td>0.128202</td>\n",
       "      <td>0.003605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12569</th>\n",
       "      <td>bed</td>\n",
       "      <td>0.582735</td>\n",
       "      <td>0.231646</td>\n",
       "      <td>-0.549904</td>\n",
       "      <td>0.999665</td>\n",
       "      <td>0.593195</td>\n",
       "      <td>0.194960</td>\n",
       "      <td>-0.514371</td>\n",
       "      <td>0.999619</td>\n",
       "      <td>0.601733</td>\n",
       "      <td>...</td>\n",
       "      <td>0.483065</td>\n",
       "      <td>0.003722</td>\n",
       "      <td>0.601851</td>\n",
       "      <td>1.825967</td>\n",
       "      <td>0.144897</td>\n",
       "      <td>0.002096</td>\n",
       "      <td>0.512101</td>\n",
       "      <td>1.814257</td>\n",
       "      <td>0.183510</td>\n",
       "      <td>0.004054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12570</th>\n",
       "      <td>bed</td>\n",
       "      <td>0.583797</td>\n",
       "      <td>0.228436</td>\n",
       "      <td>-0.610396</td>\n",
       "      <td>0.999688</td>\n",
       "      <td>0.594404</td>\n",
       "      <td>0.193720</td>\n",
       "      <td>-0.574524</td>\n",
       "      <td>0.999641</td>\n",
       "      <td>0.602766</td>\n",
       "      <td>...</td>\n",
       "      <td>0.510541</td>\n",
       "      <td>0.004981</td>\n",
       "      <td>0.603092</td>\n",
       "      <td>1.825737</td>\n",
       "      <td>0.128428</td>\n",
       "      <td>0.002894</td>\n",
       "      <td>0.512202</td>\n",
       "      <td>1.814188</td>\n",
       "      <td>0.213240</td>\n",
       "      <td>0.005547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12571</th>\n",
       "      <td>bed</td>\n",
       "      <td>0.585292</td>\n",
       "      <td>0.225537</td>\n",
       "      <td>-0.606941</td>\n",
       "      <td>0.999693</td>\n",
       "      <td>0.595918</td>\n",
       "      <td>0.191964</td>\n",
       "      <td>-0.570239</td>\n",
       "      <td>0.999643</td>\n",
       "      <td>0.604145</td>\n",
       "      <td>...</td>\n",
       "      <td>0.498834</td>\n",
       "      <td>0.005538</td>\n",
       "      <td>0.607218</td>\n",
       "      <td>1.827818</td>\n",
       "      <td>0.120828</td>\n",
       "      <td>0.003624</td>\n",
       "      <td>0.515186</td>\n",
       "      <td>1.817711</td>\n",
       "      <td>0.201774</td>\n",
       "      <td>0.006492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12572</th>\n",
       "      <td>bed</td>\n",
       "      <td>0.585755</td>\n",
       "      <td>0.223811</td>\n",
       "      <td>-0.567971</td>\n",
       "      <td>0.999695</td>\n",
       "      <td>0.596428</td>\n",
       "      <td>0.191312</td>\n",
       "      <td>-0.531835</td>\n",
       "      <td>0.999640</td>\n",
       "      <td>0.604642</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408466</td>\n",
       "      <td>0.005802</td>\n",
       "      <td>0.612995</td>\n",
       "      <td>1.827712</td>\n",
       "      <td>0.118651</td>\n",
       "      <td>0.004350</td>\n",
       "      <td>0.526171</td>\n",
       "      <td>1.818134</td>\n",
       "      <td>0.122340</td>\n",
       "      <td>0.006794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12573</th>\n",
       "      <td>bed</td>\n",
       "      <td>0.586038</td>\n",
       "      <td>0.221116</td>\n",
       "      <td>-0.516151</td>\n",
       "      <td>0.999698</td>\n",
       "      <td>0.596938</td>\n",
       "      <td>0.188967</td>\n",
       "      <td>-0.480259</td>\n",
       "      <td>0.999630</td>\n",
       "      <td>0.605132</td>\n",
       "      <td>...</td>\n",
       "      <td>0.233419</td>\n",
       "      <td>0.008177</td>\n",
       "      <td>0.621568</td>\n",
       "      <td>1.823408</td>\n",
       "      <td>0.002734</td>\n",
       "      <td>0.007983</td>\n",
       "      <td>0.535599</td>\n",
       "      <td>1.814611</td>\n",
       "      <td>-0.051684</td>\n",
       "      <td>0.008531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12574 rows Ã— 133 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      class        x1        y1        z1        v1        x2        y2  \\\n",
       "0      want  0.523251  0.450990 -0.459594  0.999819  0.533429  0.417930   \n",
       "1      want  0.524013  0.449159 -0.515879  0.999908  0.534502  0.416850   \n",
       "2      want  0.524378  0.448990 -0.524086  0.999916  0.534832  0.416744   \n",
       "3      want  0.525125  0.448920 -0.509409  0.999923  0.535406  0.416669   \n",
       "4      want  0.525927  0.448911 -0.530385  0.999929  0.535953  0.416656   \n",
       "...     ...       ...       ...       ...       ...       ...       ...   \n",
       "12569   bed  0.582735  0.231646 -0.549904  0.999665  0.593195  0.194960   \n",
       "12570   bed  0.583797  0.228436 -0.610396  0.999688  0.594404  0.193720   \n",
       "12571   bed  0.585292  0.225537 -0.606941  0.999693  0.595918  0.191964   \n",
       "12572   bed  0.585755  0.223811 -0.567971  0.999695  0.596428  0.191312   \n",
       "12573   bed  0.586038  0.221116 -0.516151  0.999698  0.596938  0.188967   \n",
       "\n",
       "             z2        v2        x3  ...       z31       v31       x32  \\\n",
       "0     -0.431221  0.999746  0.539272  ...  0.297255  0.010767  0.526460   \n",
       "1     -0.491419  0.999874  0.540472  ...  0.423895  0.005330  0.554579   \n",
       "2     -0.500241  0.999885  0.540848  ...  0.435331  0.004874  0.554528   \n",
       "3     -0.486281  0.999894  0.541555  ...  0.419291  0.004455  0.553707   \n",
       "4     -0.506059  0.999903  0.542202  ...  0.417702  0.004097  0.551577   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "12569 -0.514371  0.999619  0.601733  ...  0.483065  0.003722  0.601851   \n",
       "12570 -0.574524  0.999641  0.602766  ...  0.510541  0.004981  0.603092   \n",
       "12571 -0.570239  0.999643  0.604145  ...  0.498834  0.005538  0.607218   \n",
       "12572 -0.531835  0.999640  0.604642  ...  0.408466  0.005802  0.612995   \n",
       "12573 -0.480259  0.999630  0.605132  ...  0.233419  0.008177  0.621568   \n",
       "\n",
       "            y32       z32       v32       x33       y33       z33       v33  \n",
       "0      1.816151 -0.012140  0.006274  0.441641  1.810452  0.018783  0.009043  \n",
       "1      1.776513  0.108589  0.003069  0.477024  1.773829  0.141674  0.004596  \n",
       "2      1.776742  0.098729  0.002805  0.476732  1.773951  0.149873  0.004227  \n",
       "3      1.776260  0.100837  0.002565  0.476286  1.773094  0.135557  0.003885  \n",
       "4      1.776931  0.101532  0.002363  0.473619  1.773873  0.128202  0.003605  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "12569  1.825967  0.144897  0.002096  0.512101  1.814257  0.183510  0.004054  \n",
       "12570  1.825737  0.128428  0.002894  0.512202  1.814188  0.213240  0.005547  \n",
       "12571  1.827818  0.120828  0.003624  0.515186  1.817711  0.201774  0.006492  \n",
       "12572  1.827712  0.118651  0.004350  0.526171  1.818134  0.122340  0.006794  \n",
       "12573  1.823408  0.002734  0.007983  0.535599  1.814611 -0.051684  0.008531  \n",
       "\n",
       "[12574 rows x 133 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['class'] = df_train['class'].replace(\"don't want\", \"don't_want\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['want', \"don't_want\", 'more', 'potty', 'dirty', 'clean', 'home',\n",
       "       'school', 'play', 'bed'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "don't_want    1576\n",
       "want          1512\n",
       "potty         1489\n",
       "dirty         1339\n",
       "more          1309\n",
       "home          1137\n",
       "clean         1114\n",
       "bed           1097\n",
       "play          1023\n",
       "school         978\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop('class', axis=1)\n",
    "y = df_train['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1164          potty\n",
       "1298          potty\n",
       "9549     don't_want\n",
       "2447         school\n",
       "10721    don't_want\n",
       "            ...    \n",
       "7249          potty\n",
       "8086          potty\n",
       "8744           want\n",
       "9740           more\n",
       "12393          play\n",
       "Name: class, Length: 2515, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2 Train Machine Learning Classification Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = {\n",
    "    'lr':make_pipeline(StandardScaler(), LogisticRegression()),\n",
    "    'rc':make_pipeline(StandardScaler(), RidgeClassifier()),\n",
    "    'rf':make_pipeline(StandardScaler(), RandomForestClassifier()),\n",
    "    'gb':make_pipeline(StandardScaler(), GradientBoostingClassifier()),\n",
    "    'svm':make_pipeline(StandardScaler(), SVC())\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_models = {}\n",
    "for ml, pipeline in pipelines.items():\n",
    "    model = pipeline.fit(X_train, y_train)\n",
    "    train_models[ml] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('logisticregression', LogisticRegression())]),\n",
       " 'rc': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('ridgeclassifier', RidgeClassifier())]),\n",
       " 'rf': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('randomforestclassifier', RandomForestClassifier())]),\n",
       " 'gb': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('gradientboostingclassifier', GradientBoostingClassifier())]),\n",
       " 'svm': Pipeline(steps=[('standardscaler', StandardScaler()), ('svc', SVC())])}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['potty', 'potty', \"don't_want\", ..., 'want', 'more', 'play'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_models['lr'].predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.3 Evaluate & Select Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.9852882703777336 0.9853582795373249 0.9852882703777336\n",
      "rc 0.9614314115308151 0.962682110645092 0.9614314115308151\n",
      "rf 0.9992047713717693 0.9992098853822403 0.9992047713717693\n",
      "gb 0.9944333996023856 0.9944553458651288 0.9944333996023856\n",
      "svm 0.9892644135188867 0.9893318684020387 0.9892644135188867\n"
     ]
    }
   ],
   "source": [
    "for ml, model in train_models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(ml, accuracy_score(y_test.values, y_pred), \n",
    "          precision_score(y_test.values, y_pred, average='weighted'), # average='micro','macro', 'weighted' / pos_label='class name'\n",
    "          recall_score(y_test.values, y_pred, average='weighted')) # average='micro','macro', 'weighted' / pos_label='class name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = train_models['lr'].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['potty', 'potty', \"don't_want\", 'school', \"don't_want\",\n",
       "       \"don't_want\", 'potty', 'clean', 'home', 'dirty'], dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1164          potty\n",
       "1298          potty\n",
       "9549     don't_want\n",
       "2447         school\n",
       "10721    don't_want\n",
       "10707    don't_want\n",
       "11907         potty\n",
       "3880          clean\n",
       "5733           home\n",
       "4524          dirty\n",
       "Name: class, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[209   0   0   0   1   0   0   0   0   1]\n",
      " [  0 241   0   0   0   0   0   0   2   0]\n",
      " [  0   0 250   0   0   0   0   0   0   0]\n",
      " [  2   0   0 303   0   1   1   0   0   2]\n",
      " [  2   0   0   0 225   0   0   5   2   0]\n",
      " [  0   0   0   5   0 264   0   0   0   2]\n",
      " [  0   0   0   1   0   0 192   1   0   0]\n",
      " [  0   0   1   0   0   0   0 291   0   0]\n",
      " [  0   1   0   0   0   0   0   0 206   0]\n",
      " [  0   0   0   2   0   4   0   1   0 297]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bed       0.98      0.99      0.99       211\n",
      "       clean       1.00      0.99      0.99       243\n",
      "       dirty       1.00      1.00      1.00       250\n",
      "  don't_want       0.97      0.98      0.98       309\n",
      "        home       1.00      0.96      0.98       234\n",
      "        more       0.98      0.97      0.98       271\n",
      "        play       0.99      0.99      0.99       194\n",
      "       potty       0.98      1.00      0.99       292\n",
      "      school       0.98      1.00      0.99       207\n",
      "        want       0.98      0.98      0.98       304\n",
      "\n",
      "    accuracy                           0.99      2515\n",
      "   macro avg       0.99      0.99      0.99      2515\n",
      "weighted avg       0.99      0.99      0.99      2515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('model2_3.pkl', 'wb') as f:\n",
    "#     pickle.dump(svc, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_pose.pkl', 'wb') as f:\n",
    "    pickle.dump(train_models['lr'], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Make Detections with Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_pose.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained MTCNN model\n",
    "mtcnn = MTCNN(keep_all=True, device=torch.device('cuda:0' if torch.cuda.is_available() else 'cpu'))\n",
    "\n",
    "cap = cv2.VideoCapture('./datatest.mp4')\n",
    "# cap = cv2.VideoCapture(0)\n",
    "\n",
    "# # Get the original frame rate\n",
    "original_frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# # # Set the frame rate of the capture to the original frame rate\n",
    "cap.set(cv2.CAP_PROP_FPS, original_frame_rate)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "output_video = cv2.VideoWriter('Detection2_2.mp4', fourcc, original_frame_rate, (int(cap.get(3)), int(cap.get(4))))\n",
    "\n",
    "# Setup Mediapipe instance\n",
    "counter = 0\n",
    "stage = None\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5,\n",
    "                  min_tracking_confidence=0.5) as pose:\n",
    "    with mp_hands.Hands(static_image_mode=True, max_num_hands=2, min_detection_confidence=0.5) as hands:\n",
    "\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"Stream stopped.\")\n",
    "                break\n",
    "\n",
    "            # Perform face detection\n",
    "            boxes, probs = mtcnn.detect(frame)\n",
    "\n",
    "            if boxes is not None:\n",
    "                for box in boxes:\n",
    "                    x, y, width, height = map(int, box)\n",
    "                    \n",
    "                    padding_percentage = 0.1  # 10% of the box size\n",
    "                    padding_x = int((width - x) * padding_percentage)\n",
    "                    padding_y = int((height - y) * padding_percentage)\n",
    "\n",
    "                    x -= padding_x\n",
    "                    y -= padding_y\n",
    "                    width += 2 * padding_x\n",
    "                    height += 2 * padding_y\n",
    "\n",
    "                    cv2.rectangle(frame, (x, y), (width, height), (0, 0, 255), 2)\n",
    "            \n",
    "            # Recolor image to RGB\n",
    "            frame.flags.writeable = False\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            results = pose.process(frame)\n",
    "            results_h = hands.process(frame)\n",
    "\n",
    "            # Recolor back to BRG\n",
    "            frame.flags.writeable = True\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            # Extract landmarks\n",
    "            try:\n",
    "                lanmarks = results.pose_landmarks.landmark\n",
    "\n",
    "                # Get coordinates\n",
    "                shoulder = [lanmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, lanmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "                elbow = [lanmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x, lanmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "                wrist = [lanmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x, lanmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "                \n",
    "                shoulder1 = [lanmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x, lanmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "                elbow1 = [lanmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x, lanmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "                wrist1 = [lanmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x, lanmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "                \n",
    "                # Calculate angle\n",
    "                triangle = calculateangle(shoulder, elbow, wrist).round(2)\n",
    "                triangle2 = calculateangle(shoulder1, elbow1, wrist1).round(2)\n",
    "                # print(angle)\n",
    "\n",
    "                # Visualize triangle shoulder, elbow, wrist\n",
    "                cv2.putText(frame, str(triangle),\n",
    "                            (int(elbow[0]*frame.shape[1]), int(elbow[1]*frame.shape[0])),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 2, cv2.LINE_AA)\n",
    "                \n",
    "                # Visualize triangle shoulder1, elbow1, wrist1\n",
    "                cv2.putText(frame, str(triangle2),\n",
    "                            (int(elbow1[0]*frame.shape[1]), int(elbow1[1]*frame.shape[0])),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 2, cv2.LINE_AA)\n",
    "                \n",
    "                # Curl Counter Logic\n",
    "                if triangle2 > 155:\n",
    "                    stage = \"down\"\n",
    "                if triangle2 < 30 and stage =='down':\n",
    "                    stage=\"up\"\n",
    "                    counter +=1\n",
    "                    \n",
    "                if stage == \"up\":\n",
    "                    row = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten().tolist()\n",
    "                    X = pd.DataFrame([row], columns=landmarks_2[1:])\n",
    "                    body_class = model.predict(X)[0]\n",
    "                    prob = model.predict_proba(X)[0]\n",
    "                    # print(body_class, prob)\n",
    "                if stage == \"down\":\n",
    "                    body_class = 'Stand'\n",
    "                    prob = 1.0\n",
    "                    \n",
    "\n",
    "                # Render detections\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    frame,\n",
    "                    results.pose_landmarks,\n",
    "                    mp_pose.POSE_CONNECTIONS,\n",
    "                    mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2),\n",
    "                    mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2))\n",
    "                    # landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n",
    "                \n",
    "                if results_h.multi_hand_landmarks:\n",
    "                    for hand_landmarks in results_h.multi_hand_landmarks:\n",
    "                        mp_draw.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "                # Render curl counter\n",
    "                # Setup status box\n",
    "                cv2.rectangle(frame, (0,0), (250,80), (245,117,16), -1)\n",
    "                \n",
    "                # Rep data\n",
    "                cv2.putText(frame, 'REPS', (15,12), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)\n",
    "                cv2.putText(frame, str(counter), \n",
    "                            (10,65), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 2, cv2.LINE_AA)\n",
    "                \n",
    "                # Stage data\n",
    "                cv2.putText(frame, 'STAGE', (65,12), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)\n",
    "                cv2.putText(frame, stage, \n",
    "                            (90,65), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 2, cv2.LINE_AA)\n",
    "                \n",
    "                #  Display class\n",
    "                cv2.rectangle(frame, (600,0), (250,80), (0,0,255), -1)\n",
    "                cv2.putText(frame, 'CLASS',\n",
    "                            (300,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)\n",
    "                cv2.putText(frame, body_class.split(' ')[0],\n",
    "                            (285,60), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "                \n",
    "                # Display Probbability\n",
    "                cv2.putText(frame, 'PROB',\n",
    "                            (500,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)\n",
    "                cv2.putText(frame, str(round(prob[np.argmax(prob)], 2)),\n",
    "                            (500,60), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "                \n",
    "                # Display on Face Detection\n",
    "                cv2.putText(frame, f'Class: {body_class.split(\" \")[0]}', (x, y - 10), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "                cv2.putText(frame, f'Prob: {str(round(prob[np.argmax(prob)], 2))}', (x, y+260), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            # Write the frame to the output video file\n",
    "            output_video.write(frame)\n",
    "\n",
    "            cv2.imshow('MediaPipe Pose', frame)\n",
    "            \n",
    "            if cv2.waitKey(1) == ord('q'):\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        output_video.release()\n",
    "        cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Group 8**\n",
    "1. à¸™à¸²à¸¢à¸˜à¸™à¸ à¸±à¸—à¸£ à¸¨à¸£à¸µà¹€à¸žà¹‡à¸Šà¸£ 66076020\n",
    "2. à¸à¸™à¸à¸¨à¸±à¸à¸”à¸´à¹Œ à¹€à¸Šà¸²à¸§à¹Œà¹€à¸¥à¸´à¸¨ 66076002\n",
    "3. à¸›à¸§à¸´à¸™à¸à¸²à¸™ à¸ªà¸²à¸£à¸—à¸—à¸­à¸‡ 66076028"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('./Detection2_2.mp4')\n",
    "# Setup Mediapipe instance\n",
    "    \n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Stream stopped.\")\n",
    "        break\n",
    "    \n",
    "    cv2.imshow('MediaPipe Pose', frame)\n",
    "    \n",
    "    if cv2.waitKey(20) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
